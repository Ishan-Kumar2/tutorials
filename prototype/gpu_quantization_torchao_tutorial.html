


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>(prototype) GPU Quantization with TorchAO &mdash; PyTorch Tutorials 2.4.0+cu121 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.10/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/katex-math.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sg_gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom2.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T8XT4PS');</script>
    <!-- End Google Tag Manager -->
  

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>

          <li class="main-menu-item">
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Learn
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/get-started">
                  <span class=dropdown-title>Get Started</span>
                  <p>Run PyTorch locally or get started quickly with one of the supported cloud platforms</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials">
                  <span class="dropdown-title">Tutorials</span>
                  <p>Whats new in PyTorch tutorials</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/basics/intro.html">
                  <span class="dropdown-title">Learn the Basics</span>
                  <p>Familiarize yourself with PyTorch concepts and modules</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/recipes/recipes_index.html">
                  <span class="dropdown-title">PyTorch Recipes</span>
                  <p>Bite-size, ready-to-deploy PyTorch code examples</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/tutorials/beginner/introyt.html">
                  <span class="dropdown-title">Intro to PyTorch - YouTube Series</span>
                  <p>Master PyTorch basics with our engaging YouTube tutorial series</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Ecosystem
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem">
                  <span class="dropdown-title">Tools</span>
                  <p>Learn about the tools and frameworks in the PyTorch Ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class=dropdown-title>Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class=dropdown-title>Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class=dropdown-title>Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/ecosystem/contributor-awards-2023">
                  <span class="dropdown-title">Contributor Awards - 2023</span>
                  <p>Award winners announced at this year's PyTorch Conference</p>
                </a>
              </div>
            </div>
          </li>

          <li>
          <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Edge
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/edge">
                  <span class="dropdown-title">About PyTorch Edge</span>
                  <p>Build innovative and privacy-aware AI experiences for edge devices</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/executorch-overview">
                  <span class="dropdown-title">ExecuTorch</span>
                  <p>End-to-end solution for enabling on-device inference capabilities across mobile and edge devices</p>
                </a>
              </div>
            </div>  
          </li>

          <li class="main-menu-item">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p>Explore the documentation for comprehensive guidance on how to use PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/pytorch-domains">
                  <span class="dropdown-title">PyTorch Domains</span>
                  <p>Read the PyTorch Domains documentation to learn more about domain-specific libraries</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                Blogs & News 
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/blog/">
                  <span class="dropdown-title">PyTorch Blog</span>
                  <p>Catch up on the latest technical news and happenings</p>
                </a>
                 <a class="nav-dropdown-item" href="https://pytorch.org/community-blog">
                  <span class="dropdown-title">Community Blog</span>
                  <p>Stories from the PyTorch ecosystem</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/videos">
                  <span class="dropdown-title">Videos</span>
                  <p>Learn about the latest PyTorch tutorials, new, and more </p>
                <a class="nav-dropdown-item" href="https://pytorch.org/community-stories">
                  <span class="dropdown-title">Community Stories</span>
                  <p>Learn how our community solves real, everyday machine learning problems with PyTorch</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/events">
                  <span class="dropdown-title">Events</span>
                  <p>Find events, webinars, and podcasts</p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="with-down-arrow">
                About
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/foundation">
                  <span class="dropdown-title">PyTorch Foundation</span>
                  <p>Learn more about the PyTorch Foundation</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/governing-board">
                  <span class="dropdown-title">Governing Board</span>
                  <p></p>
                </a>
              </div>
            </div>
          </li>

          <li class="main-menu-item">
            <div class="no-dropdown">
              <a href="https://pytorch.org/join" data-cta="join">
                Become a Member
              </a>
            </div>
          </li>
          <li>
           <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="github-icon">
             </a>
           </div>
          </li>
          <!--- TODO: This block adds the search icon to the nav bar. We will enable it later. 
          <li>
            <div class="main-menu-item">
             <a href="https://github.com/pytorch/pytorch" class="search-icon">
             </a>
            </div>
          </li>
          --->
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  2.4.0+cu121
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Tutorials" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption" role="heading"><span class="caption-text">PyTorch Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../recipes/recipes_index.html">See All Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="prototype_index.html">See All Prototype Recipes</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/intro.html">Learn the Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/quickstart_tutorial.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/tensorqs_tutorial.html">Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/data_tutorial.html">Datasets &amp; DataLoaders</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/transforms_tutorial.html">Transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/buildmodel_tutorial.html">Build the Neural Network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/autogradqs_tutorial.html">Automatic Differentiation with <code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/optimization_tutorial.html">Optimizing Model Parameters</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/saveloadrun_tutorial.html">Save and Load the Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/custom_ops_landing_page.html">PyTorch Custom Operators</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Introduction to PyTorch on YouTube</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt.html">Introduction to PyTorch - YouTube Series</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/introyt1_tutorial.html">Introduction to PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/tensors_deeper_tutorial.html">Introduction to PyTorch Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/autogradyt_tutorial.html">The Fundamentals of Autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/modelsyt_tutorial.html">Building Models with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/tensorboardyt_tutorial.html">PyTorch TensorBoard Support</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/trainingyt.html">Training with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/introyt/captumyt.html">Model Understanding with Captum</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Learning PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_tutorial.html">Visualizing Models, Data, and Training with TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pinmem_nonblock.html">A guide on good usage of <code class="docutils literal notranslate"><span class="pre">non_blocking</span></code> and <code class="docutils literal notranslate"><span class="pre">pin_memory()</span></code> in PyTorch</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Image and Video</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/spatial_transformer_tutorial.html">Spatial Transformer Networks Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/vt_tutorial.html">Optimizing Vision Transformer Model for Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tiatoolbox_tutorial.html">Whole Slide Image Classification Using PyTorch and TIAToolbox</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Audio</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_io_tutorial.html">Audio I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_resampling_tutorial.html">Audio Resampling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_data_augmentation_tutorial.html">Audio Data Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_feature_extractions_tutorial.html">Audio Feature Extractions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_feature_augmentation_tutorial.html">Audio Feature Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_datasets_tutorial.html">Audio Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/speech_recognition_pipeline_tutorial.html">Speech Recognition with Wav2Vec2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/text_to_speech_with_torchaudio.html">Text-to-speech with Tacotron2</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/forced_alignment_with_torchaudio_tutorial.html">Forced Alignment with Wav2Vec2</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/bettertransformer_tutorial.html">Fast Transformer Inference with Better Transformer</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">NLP From Scratch: Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">NLP From Scratch: Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/text_sentiment_ngrams_tutorial.html">Text classification with the torchtext library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/translation_transformer.html">Language Translation with <code class="docutils literal notranslate"><span class="pre">nn.Transformer</span></code> and torchtext</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/torchtext_custom_dataset_tutorial.html">Preprocess custom text dataset using Torchtext</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Backends</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/onnx/intro_onnx.html">Introduction to ONNX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_ppo.html">Reinforcement Learning (PPO) with TorchRL Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/mario_rl_tutorial.html">Train a Mario-playing RL Agent</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/pendulum.html">Pendulum: Writing your environment and transforms with TorchRL</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Deploying PyTorch Models in Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/onnx/intro_onnx.html">Introduction to ONNX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/flask_rest_api_tutorial.html">Deploying PyTorch in Python via a REST API with Flask</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/Intro_to_TorchScript_tutorial.html">Introduction to TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_export.html">Loading a TorchScript Model in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/super_resolution_with_onnxruntime.html">(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/realtime_rpi.html">Real Time Inference on Raspberry Pi 4 (30 fps!)</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Profiling PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/profiler.html">Profiling your PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/hta_intro_tutorial.html">Introduction to Holistic Trace Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/hta_trace_diff_tutorial.html">Trace Diff using Holistic Trace Analysis</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Code Transforms with FX</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/fx_conv_bn_fuser.html">(beta) Building a Convolution/Batch Norm fuser in FX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/fx_profiling_tutorial.html">(beta) Building a Simple CPU Performance Profiler with FX</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Frontend APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/forward_ad_usage.html">Forward-mode Automatic Differentiation (Beta)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/jacobians_hessians.html">Jacobians, Hessians, hvp, vhp, and more: composing function transforms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ensembling.html">Model ensembling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/per_sample_grads.html">Per-sample-gradients</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_autograd.html">Autograd in C++ Frontend</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Extending PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../advanced/custom_ops_landing_page.html">PyTorch Custom Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/python_custom_ops.html">Python Custom Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_custom_ops.html">Custom C++ and CUDA Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/custom_function_double_backward_tutorial.html">Double Backward with Custom Functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/custom_function_conv_bn_tutorial.html">Fusing Convolution and Batch Norm using Custom Function</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dispatcher.html">Registering a Dispatched Operator in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/extend_dispatcher.html">Extending dispatcher for a new backend in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/privateuseone.html">Facilitating New Backend Integration by PrivateUse1</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/profiler.html">Profiling your PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_profiler_tutorial.html">PyTorch Profiler With TensorBoard</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/hyperparameter_tuning_tutorial.html">Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/vt_tutorial.html">Optimizing Vision Transformer Model for Deployment</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/parametrizations.html">Parametrizations Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dynamic_quantization_bert_tutorial.html">(beta) Dynamic Quantization on BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/quantized_transfer_learning_tutorial.html">(beta) Quantized Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/static_quantization_tutorial.html">(beta) Static Quantization with Eager Mode in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchserve_with_ipex.html">Grokking PyTorch Intel CPU performance from first principles</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchserve_with_ipex_2.html">Grokking PyTorch Intel CPU performance from first principles (Part 2)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/nvfuser_intro_tutorial.html">Getting Started - Accelerate Your Scripts with nvFuser</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ax_multiobjective_nas_tutorial.html">Multi-Objective NAS with Ax</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torch_compile_tutorial.html">Introduction to <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/inductor_debug_cpu.html">Inductor CPU backend debugging and profiling</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/scaled_dot_product_attention_tutorial.html">(Beta) Implementing High-Performance Transformers with Scaled Dot Product Attention (SDPA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/scaled_dot_product_attention_tutorial.html#using-sdpa-with-torch-compile">Using SDPA with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/scaled_dot_product_attention_tutorial.html#using-sdpa-with-attn-bias-subclasses">Using SDPA with attn_bias subclasses`</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/scaled_dot_product_attention_tutorial.html#conclusion">Conclusion</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/knowledge_distillation_tutorial.html">Knowledge Distillation Tutorial</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Parallel and Distributed Training</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../distributed/home.html">Distributed and Parallel Training Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/ddp_series_intro.html">Distributed Data Parallel in PyTorch - Video Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">Single-Machine Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/FSDP_tutorial.html">Getting Started with Fully Sharded Data Parallel(FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/FSDP_adavnced_tutorial.html">Advanced Model Training with Fully Sharded Data Parallel (FSDP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/TCPStore_libuv_backend.html">Introduction to Libuv TCPStore Backend</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/TP_tutorial.html">Large Scale Transformer model training with Tensor Parallel (TP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pipelining_tutorial.html">Introduction to Distributed Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/process_group_cpp_extension_tutorial.html">Customize Process Group Backends Using Cpp Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/generic_join.html">Distributed Training with Uneven Inputs Using the Join Context Manager</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Edge with ExecuTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/tutorials/export-to-executorch-tutorial.html">Exporting to ExecuTorch Tutorial</a></li>
<li class="toctree-l1"><a class="reference external" href=" https://pytorch.org/executorch/stable/running-a-model-cpp-tutorial.html">Running an ExecuTorch Model in C++ Tutorial</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/tutorials/sdk-integration-tutorial.html">Using the ExecuTorch SDK to Profile a Model</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/demo-apps-ios.html">Building an ExecuTorch iOS Demo App</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/demo-apps-android.html">Building an ExecuTorch Android Demo App</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/executorch/stable/examples-end-to-end-to-lower-model-to-delegate.html">Lowering a Model as a Delegate</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Recommendation Systems</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchrec_tutorial.html">Introduction to TorchRec</a></li>
<li class="toctree-l1"><a class="reference internal" href="../advanced/sharding.html">Exploring TorchRec sharding</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Multimodality</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/flava_finetuning_tutorial.html">TorchMultimodal Tutorial: Finetuning FLAVA</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>

        
      <li>(prototype) GPU Quantization with TorchAO</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/prototype/gpu_quantization_torchao_tutorial.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <div class="pytorch-call-to-action-links">
            <div id="tutorial-type">prototype/gpu_quantization_torchao_tutorial</div>

            <div id="google-colab-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
              <div class="call-to-action-desktop-view">Run in Google Colab</div>
              <div class="call-to-action-mobile-view">Colab</div>
            </div>
            <div id="download-notebook-link">
              <img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
              <div class="call-to-action-desktop-view">Download Notebook</div>
              <div class="call-to-action-mobile-view">Notebook</div>
            </div>
            <div id="github-view-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
              <div class="call-to-action-desktop-view">View on GitHub</div>
              <div class="call-to-action-mobile-view">GitHub</div>
            </div>
          </div>

        

          <!-- Google Tag Manager (noscript) -->
          <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T8XT4PS"
          height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
          <!-- End Google Tag Manager (noscript) -->
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="sphx-glr-download-link-note admonition note">
<p class="admonition-title">Note</p>
<p>Click <a class="reference internal" href="#sphx-glr-download-prototype-gpu-quantization-torchao-tutorial-py"><span class="std std-ref">here</span></a>
to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="prototype-gpu-quantization-with-torchao">
<span id="sphx-glr-prototype-gpu-quantization-torchao-tutorial-py"></span><h1>(prototype) GPU Quantization with TorchAO<a class="headerlink" href="#prototype-gpu-quantization-with-torchao" title="Permalink to this heading">¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/HDCharles">HDCharles</a></p>
<p>In this tutorial, we will walk you through the quantization and optimization
of the popular <a class="reference external" href="https://github.com/facebookresearch/segment-anything">segment anything model</a>. These
steps will mimic some of those taken to develop the
<a class="reference external" href="https://github.com/pytorch-labs/segment-anything-fast/blob/main/segment_anything_fast/modeling/image_encoder.py#L15">segment-anything-fast</a>
repo. This step-by-step guide demonstrates how you can
apply these techniques to speed up your own models, especially those
that use transformers. To that end, we will focus on widely applicable
techniques, such as optimizing performance with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> and
quantization and measure their impact.</p>
<div class="section" id="set-up-your-environment">
<h2>Set up Your Environment<a class="headerlink" href="#set-up-your-environment" title="Permalink to this heading">¶</a></h2>
<p>First, let’s configure your environment. This guide was written for CUDA 12.1.
We have run this tutorial on an A100-PG509-200 power limited to 330.00 W. If you
are using a different hardware, you might see different performance numbers.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&gt;<span class="w"> </span>conda<span class="w"> </span>create<span class="w"> </span>-n<span class="w"> </span>myenv<span class="w"> </span><span class="nv">python</span><span class="o">=</span><span class="m">3</span>.10
&gt;<span class="w"> </span>pip3<span class="w"> </span>install<span class="w"> </span>--pre<span class="w"> </span>torch<span class="w"> </span>torchvision<span class="w"> </span>torchaudio<span class="w"> </span>--index-url<span class="w"> </span>https://download.pytorch.org/whl/nightly/cu121
&gt;<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/facebookresearch/segment-anything.git
&gt;<span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>git+https://github.com/pytorch-labs/ao.git
</pre></div>
</div>
<p>Segment Anything Model checkpoint setup:</p>
<ol class="arabic simple">
<li><p>Go to the <a class="reference external" href="checkpointhttps://github.com/facebookresearch/segment-anything/tree/main#model-checkpoints">segment-anything repo</a> and download the <code class="docutils literal notranslate"><span class="pre">vit_h</span></code> checkpoint. Alternatively, you can just use <code class="docutils literal notranslate"><span class="pre">wget</span></code>: <a href="#id1"><span class="problematic" id="id2">`</span></a>wget <a class="reference external" href="https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth">https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth</a> –directory-prefix=&lt;path&gt;</p></li>
<li><p>Pass in that directory by editing the code below to say:</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>
</pre></div>
</div>
<p>{sam_checkpoint_base_path}=&lt;path&gt;</p>
<p>This was run on an A100-PG509-200 power limited to 330.00 W</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchao.quantization</span> <span class="kn">import</span> <span class="n">change_linear_weights_to_int8_dqtensors</span>
<span class="kn">from</span> <span class="nn">segment_anything</span> <span class="kn">import</span> <span class="n">sam_model_registry</span>
<span class="kn">from</span> <span class="nn">torch.utils.benchmark</span> <span class="kn">import</span> <a href="https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.utils.timer.Timer" class="sphx-glr-backref-module-torch-utils-benchmark-utils-timer sphx-glr-backref-type-py-class"><span class="n">Timer</span></a>

<span class="n">sam_checkpoint_base_path</span> <span class="o">=</span> <span class="s2">&quot;data&quot;</span>
<span class="n">model_type</span> <span class="o">=</span> <span class="s1">&#39;vit_h&#39;</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;sam_vit_h_4b8939.pth&#39;</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">sam_checkpoint_base_path</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="n">batchsize</span> <span class="o">=</span> <span class="mi">16</span>
<span class="n">only_one_block</span> <span class="o">=</span> <span class="kc">True</span>


<span class="nd">@torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">benchmark</span><span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
        <span class="n">f</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <a href="https://pytorch.org/docs/stable/generated/torch.cuda.synchronize.html#torch.cuda.synchronize" title="torch.cuda.synchronize" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">synchronize</span></a><span class="p">()</span>

    <a href="https://pytorch.org/docs/stable/generated/torch.cuda.reset_peak_memory_stats.html#torch.cuda.reset_peak_memory_stats" title="torch.cuda.reset_peak_memory_stats" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">reset_peak_memory_stats</span></a><span class="p">()</span>
    <span class="n">t0</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/benchmark_utils.html#torch.utils.benchmark.Timer" title="torch.utils.benchmark.utils.timer.Timer" class="sphx-glr-backref-module-torch-utils-benchmark-utils-timer sphx-glr-backref-type-py-class"><span class="n">Timer</span></a><span class="p">(</span>
        <span class="n">stmt</span><span class="o">=</span><span class="s2">&quot;f(*args, **kwargs)&quot;</span><span class="p">,</span> <span class="nb">globals</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;args&quot;</span><span class="p">:</span> <span class="n">args</span><span class="p">,</span> <span class="s2">&quot;kwargs&quot;</span><span class="p">:</span> <span class="n">kwargs</span><span class="p">,</span> <span class="s2">&quot;f&quot;</span><span class="p">:</span> <span class="n">f</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">res</span> <span class="o">=</span> <span class="n">t0</span><span class="o">.</span><span class="n">adaptive_autorange</span><span class="p">(</span><span class="mf">.03</span><span class="p">,</span> <span class="n">min_run_time</span><span class="o">=</span><span class="mf">.2</span><span class="p">,</span> <span class="n">max_run_time</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
    <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;time&#39;</span><span class="p">:</span><span class="n">res</span><span class="o">.</span><span class="n">median</span> <span class="o">*</span> <span class="mf">1e3</span><span class="p">,</span> <span class="s1">&#39;memory&#39;</span><span class="p">:</span> <a href="https://pytorch.org/docs/stable/generated/torch.cuda.max_memory_allocated.html#torch.cuda.max_memory_allocated" title="torch.cuda.max_memory_allocated" class="sphx-glr-backref-module-torch-cuda sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">max_memory_allocated</span></a><span class="p">()</span><span class="o">/</span><span class="mf">1e9</span><span class="p">}</span>

<span class="k">def</span> <span class="nf">get_sam_model</span><span class="p">(</span><span class="n">only_one_block</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">batchsize</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
    <span class="n">sam</span> <span class="o">=</span> <span class="n">sam_model_registry</span><span class="p">[</span><span class="n">model_type</span><span class="p">](</span><span class="n">checkpoint</span><span class="o">=</span><span class="n">checkpoint_path</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">sam</span><span class="o">.</span><span class="n">image_encoder</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
    <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="n">batchsize</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>

    <span class="c1"># code to use just a single block of the model</span>
    <span class="k">if</span> <span class="n">only_one_block</span><span class="p">:</span>
        <span class="n">model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.ModuleList.html#torch.nn.ModuleList" title="torch.nn.ModuleList" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">model</span><span class="o">.</span><span class="n">blocks</span></a><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.randn.html#torch.randn" title="torch.randn" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">randn</span></a><span class="p">(</span><span class="n">batchsize</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">1280</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a>
</pre></div>
</div>
<p>In this tutorial, we focus on quantizing the <code class="docutils literal notranslate"><span class="pre">image_encoder</span></code> because the
inputs to it are statically sized while the prompt encoder and mask
decoder have variable sizes which makes them harder to quantize.</p>
<p>We’ll focus on just a single block at first to make the analysis easier.</p>
<p>Let’s start by measuring the baseline runtime.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <span class="n">get_sam_model</span><span class="p">(</span><span class="n">only_one_block</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
    <span class="n">fp32_res</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;base fp32 runtime of the model is </span><span class="si">{</span><span class="n">fp32_res</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">ms and peak memory </span><span class="si">{</span><span class="n">fp32_res</span><span class="p">[</span><span class="s1">&#39;memory&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">GB&quot;</span><span class="p">)</span>
    <span class="c1"># base fp32 runtime of the model is 186.16ms and peak memory 6.33GB</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;unable to run fp32 model: &quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>base fp32 runtime of the model is 199.59ms and peak memory 8.48GB
</pre></div>
</div>
<p>We can achieve an instant performance boost by converting the model to bfloat16.
The reason we opt for bfloat16 over fp16 is due to its dynamic range, which is comparable to
that of fp32. Both bfloat16 and fp32 possess 8 exponential bits, whereas fp16 only has 4. This
larger dynamic range helps protect us from overflow errors and other issues that can arise
when scaling and rescaling tensors due to quantization.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <span class="n">get_sam_model</span><span class="p">(</span><span class="n">only_one_block</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to" title="torch.nn.Module.to" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">to</span></a><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span></a><span class="p">)</span>
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span></a><span class="p">)</span>
<span class="n">bf16_res</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;bf16 runtime of the block is </span><span class="si">{</span><span class="n">bf16_res</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">ms and peak memory </span><span class="si">{</span><span class="n">bf16_res</span><span class="p">[</span><span class="s1">&#39;memory&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">GB&quot;</span><span class="p">)</span>
<span class="c1"># bf16 runtime of the block is 25.43ms and peak memory  3.17GB</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>bf16 runtime of the block is 70.49ms and peak memory  5.33GB
</pre></div>
</div>
<p>Just this quick change improves runtime by a factor of ~7x in the tests we have
conducted (186.16ms to 25.43ms).</p>
<p>Next, let’s use <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> with our model to see how much the performance
improves.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">model_c</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max-autotune&#39;</span><span class="p">)</span>
<span class="n">comp_res</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">model_c</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;bf16 compiled runtime of the block is </span><span class="si">{</span><span class="n">comp_res</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">ms and peak memory </span><span class="si">{</span><span class="n">comp_res</span><span class="p">[</span><span class="s1">&#39;memory&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">GB&quot;</span><span class="p">)</span>
<span class="c1"># bf16 compiled runtime of the block is 19.95ms and peak memory  2.24GB</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>AUTOTUNE mm(65536x1280, 1280x5120)
  triton_mm_124 12.4854 ms 100.0%
  triton_mm_121 12.5146 ms 99.8%
  triton_mm_117 12.6211 ms 98.9%
  triton_mm_119 12.6740 ms 98.5%
  triton_mm_122 13.0524 ms 95.7%
  mm 13.0700 ms 95.5%
  triton_mm_114 13.0892 ms 95.4%
  triton_mm_118 13.2122 ms 94.5%
  triton_mm_115 13.2555 ms 94.2%
  triton_mm_125 13.7712 ms 90.7%
SingleProcess AUTOTUNE benchmarking takes 3.5595 seconds and 0.0136 seconds precompiling
AUTOTUNE mm(65536x5120, 5120x1280)
  triton_mm_143 12.3620 ms 100.0%
  triton_mm_138 12.5459 ms 98.5%
  mm 12.6603 ms 97.6%
  triton_mm_140 12.7759 ms 96.8%
  triton_mm_137 12.8461 ms 96.2%
  triton_mm_141 12.9464 ms 95.5%
  triton_mm_136 13.0124 ms 95.0%
  triton_mm_133 13.0754 ms 94.5%
  triton_mm_144 13.2236 ms 93.5%
  triton_mm_134 13.3715 ms 92.5%
SingleProcess AUTOTUNE benchmarking takes 3.5584 seconds and 0.0011 seconds precompiling
AUTOTUNE mm(78400x1280, 1280x3840)
  triton_mm_16 11.2197 ms 100.0%
  triton_mm_13 11.3446 ms 98.9%
  triton_mm_9 11.4674 ms 97.8%
  triton_mm_11 11.4808 ms 97.7%
  mm 11.8133 ms 95.0%
  triton_mm_6 11.8417 ms 94.7%
  triton_mm_14 11.8445 ms 94.7%
  triton_mm_7 12.0135 ms 93.4%
  triton_mm_10 12.0839 ms 92.8%
  triton_mm_17 12.3659 ms 90.7%
SingleProcess AUTOTUNE benchmarking takes 3.4644 seconds and 0.0012 seconds precompiling
AUTOTUNE bmm(6400x196x80, 6400x80x196)
  triton_bmm_29 1.8303 ms 100.0%
  triton_bmm_33 1.8420 ms 99.4%
  triton_bmm_30 1.8985 ms 96.4%
  triton_bmm_25 1.9084 ms 95.9%
  triton_bmm_28 1.9169 ms 95.5%
  triton_bmm_35 1.9526 ms 93.7%
  triton_bmm_27 1.9539 ms 93.7%
  triton_bmm_32 1.9677 ms 93.0%
  triton_bmm_26 2.0203 ms 90.6%
  triton_bmm_34 2.0555 ms 89.0%
SingleProcess AUTOTUNE benchmarking takes 2.5900 seconds and 0.0012 seconds precompiling
AUTOTUNE bmm(14x89600x80, 14x80x16)
  triton_bmm_53 0.4650 ms 100.0%
  triton_bmm_39 0.4708 ms 98.8%
  triton_bmm_42 0.4753 ms 97.8%
  triton_bmm_48 0.4758 ms 97.7%
  triton_bmm_52 0.4760 ms 97.7%
  triton_bmm_45 0.4774 ms 97.4%
  bmm 0.4870 ms 95.5%
  triton_bmm_41 0.5075 ms 91.6%
  triton_bmm_40 0.5211 ms 89.2%
  triton_bmm_47 0.5289 ms 87.9%
SingleProcess AUTOTUNE benchmarking takes 2.0245 seconds and 0.0010 seconds precompiling
AUTOTUNE bmm(14x89600x80, 14x80x16)
  triton_bmm_58 0.5548 ms 100.0%
  triton_bmm_55 0.5550 ms 100.0%
  triton_bmm_64 0.5551 ms 99.9%
  triton_bmm_56 0.5763 ms 96.3%
  triton_bmm_57 0.5988 ms 92.7%
  triton_bmm_63 0.6542 ms 84.8%
  triton_bmm_66 0.6991 ms 79.4%
  triton_bmm_62 0.7087 ms 78.3%
  triton_bmm_65 0.7255 ms 76.5%
  triton_bmm_67 0.7393 ms 75.0%
SingleProcess AUTOTUNE benchmarking takes 2.0752 seconds and 0.0010 seconds precompiling
AUTOTUNE bmm(6400x196x196, 6400x196x80)
  triton_bmm_71 1.8401 ms 100.0%
  triton_bmm_81 1.8688 ms 98.5%
  triton_bmm_72 1.9722 ms 93.3%
  triton_bmm_80 1.9724 ms 93.3%
  triton_bmm_83 1.9875 ms 92.6%
  triton_bmm_77 1.9884 ms 92.5%
  triton_bmm_76 2.0388 ms 90.3%
  triton_bmm_79 2.0473 ms 89.9%
  triton_bmm_86 2.1094 ms 87.2%
  triton_bmm_84 2.1301 ms 86.4%
SingleProcess AUTOTUNE benchmarking takes 2.3173 seconds and 0.0013 seconds precompiling
AUTOTUNE mm(78400x1280, 1280x1280)
  triton_mm_98 3.7681 ms 100.0%
  triton_mm_105 3.7940 ms 99.3%
  triton_mm_102 3.7996 ms 99.2%
  triton_mm_100 3.8122 ms 98.8%
  triton_mm_99 3.8813 ms 97.1%
  triton_mm_95 3.8892 ms 96.9%
  mm 3.9575 ms 95.2%
  triton_mm_103 3.9701 ms 94.9%
  triton_mm_96 3.9788 ms 94.7%
  triton_mm_106 4.1500 ms 90.8%
SingleProcess AUTOTUNE benchmarking takes 2.5629 seconds and 0.0011 seconds precompiling
bf16 compiled runtime of the block is 62.48ms and peak memory  4.39GB
</pre></div>
</div>
<p>The first time this is run, you should see a sequence of <code class="docutils literal notranslate"><span class="pre">AUTOTUNE</span></code>
outputs which occurs when inductor compares the performance between
various kernel parameters for a kernel. This only happens once (unless
you delete your cache) so if you run the cell again you should just get
the benchmark output.</p>
<p><code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> yields about another 27% improvement. This brings the
model to a reasonable baseline where we now have to work a bit harder
for improvements.</p>
<p>Next, let’s apply quantization. Quantization for GPUs comes in three main forms
in <a class="reference external" href="https://github.com/pytorch-labs/ao">torchao</a> which is just native
pytorch+python code. This includes:</p>
<ul class="simple">
<li><p>int8 dynamic quantization</p></li>
<li><p>int8 weight-only quantization</p></li>
<li><p>int4 weight-only quantization</p></li>
</ul>
<p>Different models, or sometimes different layers in a model can require different techniques.
For models which are heavily compute bound, dynamic quantization tends
to work the best since it swaps the normal expensive floating point
matmul ops with integer versions. Weight-only quantization works better
in memory bound situations where the benefit comes from loading less
weight data, rather than doing less computation. The torchao APIs:</p>
<p><code class="docutils literal notranslate"><span class="pre">change_linear_weights_to_int8_dqtensors</span></code>,
<code class="docutils literal notranslate"><span class="pre">change_linear_weights_to_int8_woqtensors</span></code> or
<code class="docutils literal notranslate"><span class="pre">change_linear_weights_to_int4_woqtensors</span></code></p>
<p>can be used to easily apply the desired quantization technique and then
once the model is compiled with <code class="docutils literal notranslate"><span class="pre">torch.compile</span></code> with <code class="docutils literal notranslate"><span class="pre">max-autotune</span></code>, quantization is
complete and we can see our speedup.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<blockquote>
<div><p>You might experience issues with these on older versions of PyTorch. If you run
into an issue, you can use <code class="docutils literal notranslate"><span class="pre">apply_dynamic_quant</span></code> and
<code class="docutils literal notranslate"><span class="pre">apply_weight_only_int8_quant</span></code> instead as drop in replacement for the two
above (no replacement for int4).</p>
</div></blockquote>
<p>The difference between the two APIs is that <code class="docutils literal notranslate"><span class="pre">change_linear_weights</span></code> API</p>
</div>
<p>alters the weight tensor of the linear module so instead of doing a
normal linear, it does a quantized operation. This is helpful when you
have non-standard linear ops that do more than one thing. The <code class="docutils literal notranslate"><span class="pre">apply</span></code>
APIs directly swap the linear modules for a quantized module which
works on older versions but doesn’t work with non-standard linear
modules.</p>
<p>In this case Segment Anything is compute-bound so we’ll use dynamic quantization:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">del</span> <span class="n">model_c</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a>
<span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <span class="n">get_sam_model</span><span class="p">(</span><span class="n">only_one_block</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to" title="torch.nn.Module.to" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">to</span></a><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span></a><span class="p">)</span>
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span></a><span class="p">)</span>
<span class="n">change_linear_weights_to_int8_dqtensors</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">model_c</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max-autotune&#39;</span><span class="p">)</span>
<span class="n">quant_res</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">model_c</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;bf16 compiled runtime of the quantized block is </span><span class="si">{</span><span class="n">quant_res</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">ms and peak memory </span><span class="si">{</span><span class="n">quant_res</span><span class="p">[</span><span class="s1">&#39;memory&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">GB&quot;</span><span class="p">)</span>
<span class="c1"># bf16 compiled runtime of the quantized block is 19.04ms and peak memory  3.58GB</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>AUTOTUNE int_mm(65536x5120, 5120x1280)
  triton_mm_403 6.3308 ms 100.0%
  triton_mm_405 6.4673 ms 97.9%
  triton_mm_404 6.4713 ms 97.8%
  triton_mm_398 6.8068 ms 93.0%
  triton_mm_399 6.8535 ms 92.4%
  triton_mm_396 6.8908 ms 91.9%
  triton_mm_397 6.9016 ms 91.7%
  triton_mm_395 7.8720 ms 80.4%
  triton_mm_402 8.2210 ms 77.0%
  triton_mm_400 14.6407 ms 43.2%
SingleProcess AUTOTUNE benchmarking takes 1.8679 seconds and 0.0007 seconds precompiling
AUTOTUNE int_mm(78400x1280, 1280x3840)
  triton_mm_300 5.9688 ms 100.0%
  triton_mm_301 6.3558 ms 93.9%
  triton_mm_302 6.3819 ms 93.5%
  triton_mm_294 7.0004 ms 85.3%
  triton_mm_292 7.2400 ms 82.4%
  triton_mm_293 7.3272 ms 81.5%
  triton_mm_296 7.8076 ms 76.4%
  triton_mm_295 7.9307 ms 75.3%
  triton_mm_299 9.2464 ms 64.6%
  triton_mm_297 13.8289 ms 43.2%
SingleProcess AUTOTUNE benchmarking takes 1.8881 seconds and 0.0007 seconds precompiling
AUTOTUNE int_mm(78400x1280, 1280x1280)
  triton_mm_381 2.0006 ms 100.0%
  triton_mm_382 2.1812 ms 91.7%
  triton_mm_383 2.1886 ms 91.4%
  triton_mm_374 2.3455 ms 85.3%
  triton_mm_373 2.3847 ms 83.9%
  triton_mm_375 2.3850 ms 83.9%
  triton_mm_376 2.5382 ms 78.8%
  triton_mm_377 2.5842 ms 77.4%
  triton_mm_380 3.0733 ms 65.1%
  triton_mm_378 4.5168 ms 44.3%
SingleProcess AUTOTUNE benchmarking takes 1.5220 seconds and 0.0007 seconds precompiling
AUTOTUNE int_mm(65536x1280, 1280x5120)
  triton_mm_392 6.6374 ms 100.0%
  triton_mm_393 7.0797 ms 93.8%
  triton_mm_394 7.0913 ms 93.6%
  triton_mm_386 7.5838 ms 87.5%
  triton_mm_385 7.9557 ms 83.4%
  triton_mm_384 7.9800 ms 83.2%
  triton_mm_388 8.5701 ms 77.4%
  triton_mm_387 8.7348 ms 76.0%
  triton_mm_391 10.2039 ms 65.0%
  triton_mm_389 15.3251 ms 43.3%
SingleProcess AUTOTUNE benchmarking takes 1.9455 seconds and 0.0007 seconds precompiling
bf16 compiled runtime of the quantized block is 46.50ms and peak memory  4.61GB
</pre></div>
</div>
<p>With quantization, we have improved performance a bit more but memory usage increased
significantly.</p>
<p>This is for two reasons:</p>
<ol class="arabic simple">
<li><p>Quantization adds overhead to the model
since we need to quantize and dequantize the input and output. For small
batch sizes this overhead can actually make the model go slower.</p></li>
<li><p>Even though we are doing a quantized matmul, such as <code class="docutils literal notranslate"><span class="pre">int8</span> <span class="pre">x</span> <span class="pre">int8</span></code>,
the result of the multiplication gets stored in an int32 tensor
which is twice the size of the result from the non-quantized model.
If we can avoid creating this int32 tensor, our memory usage will improve a lot.</p></li>
</ol>
<p>We can fix #2 by fusing the integer matmul with the subsequent rescale
operation since the final output will be bf16, if we immediately convert
the int32 tensor to bf16 and instead store that we’ll get better
performance in terms of both runtime and memory.</p>
<p>The way to do this, is to enable the option
<code class="docutils literal notranslate"><span class="pre">force_fuse_int_mm_with_mul</span></code> in the inductor config.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">del</span> <span class="n">model_c</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a>
<span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <span class="n">get_sam_model</span><span class="p">(</span><span class="n">only_one_block</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to" title="torch.nn.Module.to" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">to</span></a><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span></a><span class="p">)</span>
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span></a><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">_inductor</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">force_fuse_int_mm_with_mul</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">change_linear_weights_to_int8_dqtensors</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">model_c</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max-autotune&#39;</span><span class="p">)</span>
<span class="n">quant_res</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">model_c</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;bf16 compiled runtime of the fused quantized block is </span><span class="si">{</span><span class="n">quant_res</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">ms and peak memory </span><span class="si">{</span><span class="n">quant_res</span><span class="p">[</span><span class="s1">&#39;memory&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">GB&quot;</span><span class="p">)</span>
<span class="c1"># bf16 compiled runtime of the fused quantized block is 18.78ms and peak memory  2.37GB</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>AUTOTUNE int_mm(78400x1280, 1280x3840, 78400x3840)
  triton_mm_528 6.1401 ms 100.0%
  triton_mm_521 6.1768 ms 99.4%
  triton_mm_520 6.6896 ms 91.8%
  triton_mm_523 6.8240 ms 90.0%
  triton_mm_529 6.9052 ms 88.9%
  triton_mm_522 6.9843 ms 87.9%
  triton_mm_524 7.4956 ms 81.9%
  triton_mm_527 8.1962 ms 74.9%
  triton_mm_530 8.5490 ms 71.8%
  triton_mm_525 13.7530 ms 44.6%
SingleProcess AUTOTUNE benchmarking takes 1.8746 seconds and 0.0014 seconds precompiling
AUTOTUNE int_mm(78400x1280, 1280x1280, 78400x1280)
  triton_mm_609 2.0378 ms 100.0%
  triton_mm_602 2.1285 ms 95.7%
  triton_mm_601 2.1927 ms 92.9%
  triton_mm_603 2.3026 ms 88.5%
  triton_mm_604 2.3475 ms 86.8%
  triton_mm_610 2.3492 ms 86.7%
  triton_mm_605 2.5557 ms 79.7%
  triton_mm_608 2.6898 ms 75.8%
  triton_mm_611 2.8931 ms 70.4%
  triton_mm_607 4.5490 ms 44.8%
SingleProcess AUTOTUNE benchmarking takes 1.5187 seconds and 0.0007 seconds precompiling
AUTOTUNE int_mm(65536x1280, 1280x5120, 65536x5120)
  triton_mm_620 6.7763 ms 100.0%
  triton_mm_613 6.8606 ms 98.8%
  triton_mm_612 7.4107 ms 91.4%
  triton_mm_615 7.6020 ms 89.1%
  triton_mm_621 7.6798 ms 88.2%
  triton_mm_614 7.7456 ms 87.5%
  triton_mm_616 8.3492 ms 81.2%
  triton_mm_619 8.9473 ms 75.7%
  triton_mm_622 9.4481 ms 71.7%
  triton_mm_617 15.2536 ms 44.4%
SingleProcess AUTOTUNE benchmarking takes 1.9416 seconds and 0.0007 seconds precompiling
AUTOTUNE int_mm(65536x5120, 5120x1280, 65536x1280)
  triton_mm_631 6.3346 ms 100.0%
  triton_mm_624 6.5075 ms 97.3%
  triton_mm_632 6.5699 ms 96.4%
  triton_mm_625 6.7065 ms 94.5%
  triton_mm_626 6.8526 ms 92.4%
  triton_mm_630 6.9505 ms 91.1%
  triton_mm_633 7.0014 ms 90.5%
  triton_mm_627 7.1281 ms 88.9%
  triton_mm_623 7.2563 ms 87.3%
  triton_mm_628 14.5190 ms 43.6%
SingleProcess AUTOTUNE benchmarking takes 1.8684 seconds and 0.0007 seconds precompiling
bf16 compiled runtime of the fused quantized block is 43.21ms and peak memory  4.47GB
</pre></div>
</div>
<p>The fusion improves performance by another small bit (about 6% over the
baseline in total) and removes almost all the memory increase, the
remaining amount (2.37GB quantized vs 2.24GB unquantized) is due to
quantization overhead which cannot be helped.</p>
<p>We’re still not done though, we can apply a few general purpose
optimizations to get our final best-case performance.</p>
<ol class="arabic simple">
<li><p>We can sometimes improve performance by disabling epilogue fusion
since the autotuning process can be confused by fusions and choose
bad kernel parameters.</p></li>
<li><p>We can apply coordinate descent tuning in all directions to enlarge
the search area for kernel parameters.</p></li>
</ol>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">del</span> <span class="n">model_c</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a>
<span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <span class="n">get_sam_model</span><span class="p">(</span><span class="n">only_one_block</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to" title="torch.nn.Module.to" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">to</span></a><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span></a><span class="p">)</span>
<a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span></a><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">_inductor</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">epilogue_fusion</span> <span class="o">=</span> <span class="kc">False</span>
<span class="n">torch</span><span class="o">.</span><span class="n">_inductor</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">coordinate_descent_tuning</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">torch</span><span class="o">.</span><span class="n">_inductor</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">coordinate_descent_check_all_directions</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">torch</span><span class="o">.</span><span class="n">_inductor</span><span class="o">.</span><span class="n">config</span><span class="o">.</span><span class="n">force_fuse_int_mm_with_mul</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">change_linear_weights_to_int8_dqtensors</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">model_c</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max-autotune&#39;</span><span class="p">)</span>
<span class="n">quant_res</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">model_c</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;bf16 compiled runtime of the final quantized block is </span><span class="si">{</span><span class="n">quant_res</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">ms and peak memory </span><span class="si">{</span><span class="n">quant_res</span><span class="p">[</span><span class="s1">&#39;memory&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">GB&quot;</span><span class="p">)</span>
<span class="c1"># bf16 compiled runtime of the final quantized block is 18.16ms and peak memory  2.39GB</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>AUTOTUNE int_mm(78400x1280, 1280x3840, 78400x3840)
  triton_mm_756 6.1403 ms 100.0%
  triton_mm_749 6.1732 ms 99.5%
  triton_mm_748 6.6869 ms 91.8%
  triton_mm_751 6.8218 ms 90.0%
  triton_mm_757 6.9060 ms 88.9%
  triton_mm_750 6.9845 ms 87.9%
  triton_mm_752 7.4976 ms 81.9%
  triton_mm_755 8.1885 ms 75.0%
  triton_mm_758 8.5510 ms 71.8%
  triton_mm_753 13.7571 ms 44.6%
SingleProcess AUTOTUNE benchmarking takes 1.9202 seconds and 0.0000 seconds precompiling
AUTOTUNE bmm(6400x196x80, 6400x80x196)
  triton_bmm_769 1.8096 ms 100.0%
  triton_bmm_773 1.8231 ms 99.3%
  triton_bmm_770 1.8974 ms 95.4%
  triton_bmm_765 1.9051 ms 95.0%
  triton_bmm_768 1.9148 ms 94.5%
  triton_bmm_767 1.9267 ms 93.9%
  triton_bmm_775 1.9528 ms 92.7%
  triton_bmm_772 1.9662 ms 92.0%
  triton_bmm_766 2.0022 ms 90.4%
  triton_bmm_774 2.0411 ms 88.7%
SingleProcess AUTOTUNE benchmarking takes 2.6533 seconds and 0.0000 seconds precompiling
AUTOTUNE bmm(14x89600x80, 14x80x16)
  triton_bmm_793 0.4647 ms 100.0%
  triton_bmm_779 0.4706 ms 98.8%
  triton_bmm_782 0.4751 ms 97.8%
  triton_bmm_788 0.4757 ms 97.7%
  triton_bmm_792 0.4759 ms 97.6%
  triton_bmm_785 0.4772 ms 97.4%
  bmm 0.4872 ms 95.4%
  triton_bmm_781 0.5081 ms 91.5%
  triton_bmm_780 0.5206 ms 89.3%
  triton_bmm_787 0.5299 ms 87.7%
SingleProcess AUTOTUNE benchmarking takes 2.0899 seconds and 0.0000 seconds precompiling
AUTOTUNE bmm(14x89600x80, 14x80x16)
  triton_bmm_795 0.5537 ms 100.0%
  triton_bmm_798 0.5539 ms 100.0%
  triton_bmm_804 0.5541 ms 99.9%
  triton_bmm_796 0.5740 ms 96.5%
  triton_bmm_797 0.5983 ms 92.5%
  triton_bmm_803 0.6559 ms 84.4%
  triton_bmm_806 0.7039 ms 78.7%
  triton_bmm_802 0.7062 ms 78.4%
  triton_bmm_805 0.7301 ms 75.8%
  triton_bmm_807 0.7436 ms 74.5%
SingleProcess AUTOTUNE benchmarking takes 2.1396 seconds and 0.0000 seconds precompiling
AUTOTUNE bmm(6400x196x196, 6400x196x80)
  triton_bmm_811 1.8319 ms 100.0%
  triton_bmm_821 1.8687 ms 98.0%
  triton_bmm_812 1.9677 ms 93.1%
  triton_bmm_820 1.9726 ms 92.9%
  triton_bmm_817 1.9776 ms 92.6%
  triton_bmm_823 1.9879 ms 92.2%
  triton_bmm_816 2.0393 ms 89.8%
  triton_bmm_819 2.0469 ms 89.5%
  triton_bmm_826 2.1099 ms 86.8%
  triton_bmm_824 2.1299 ms 86.0%
SingleProcess AUTOTUNE benchmarking takes 2.3842 seconds and 0.0000 seconds precompiling
AUTOTUNE int_mm(78400x1280, 1280x1280, 78400x1280)
  triton_mm_837 2.0375 ms 100.0%
  triton_mm_830 2.1285 ms 95.7%
  triton_mm_829 2.1931 ms 92.9%
  triton_mm_831 2.3028 ms 88.5%
  triton_mm_832 2.3475 ms 86.8%
  triton_mm_838 2.3476 ms 86.8%
  triton_mm_833 2.5507 ms 79.9%
  triton_mm_836 2.6890 ms 75.8%
  triton_mm_839 2.8931 ms 70.4%
  triton_mm_835 4.5485 ms 44.8%
SingleProcess AUTOTUNE benchmarking takes 1.5641 seconds and 0.0000 seconds precompiling
AUTOTUNE int_mm(65536x1280, 1280x5120, 65536x5120)
  triton_mm_848 6.7761 ms 100.0%
  triton_mm_841 6.8638 ms 98.7%
  triton_mm_840 7.4208 ms 91.3%
  triton_mm_843 7.6004 ms 89.2%
  triton_mm_849 7.6817 ms 88.2%
  triton_mm_842 7.7446 ms 87.5%
  triton_mm_844 8.3476 ms 81.2%
  triton_mm_847 8.9526 ms 75.7%
  triton_mm_850 9.4487 ms 71.7%
  triton_mm_845 15.2056 ms 44.6%
SingleProcess AUTOTUNE benchmarking takes 1.9865 seconds and 0.0000 seconds precompiling
AUTOTUNE int_mm(65536x5120, 5120x1280, 65536x1280)
  triton_mm_859 6.3348 ms 100.0%
  triton_mm_852 6.5223 ms 97.1%
  triton_mm_860 6.5635 ms 96.5%
  triton_mm_853 6.7239 ms 94.2%
  triton_mm_854 6.8568 ms 92.4%
  triton_mm_858 6.9551 ms 91.1%
  triton_mm_861 7.0014 ms 90.5%
  triton_mm_855 7.1421 ms 88.7%
  triton_mm_851 7.3276 ms 86.5%
  triton_mm_856 14.4318 ms 43.9%
SingleProcess AUTOTUNE benchmarking takes 1.9146 seconds and 0.0000 seconds precompiling
bf16 compiled runtime of the final quantized block is 42.34ms and peak memory  4.47GB
</pre></div>
</div>
<p>As you can see, we’ve squeezed another small improvement from the model,
taking our total improvement to over 10x compared to our original. To
get a final estimate of the impact of quantization lets do an apples to
apples comparison on the full model since the actual improvement will
differ block by block depending on the shapes involved.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">try</span><span class="p">:</span>
    <span class="k">del</span> <span class="n">model_c</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a>
    <span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <span class="n">get_sam_model</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to" title="torch.nn.Module.to" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">to</span></a><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span></a><span class="p">)</span>
    <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span></a><span class="p">)</span>
    <span class="n">model_c</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max-autotune&#39;</span><span class="p">)</span>
    <span class="n">quant_res</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">model_c</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;bf16 compiled runtime of the compiled full model is </span><span class="si">{</span><span class="n">quant_res</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">ms and peak memory </span><span class="si">{</span><span class="n">quant_res</span><span class="p">[</span><span class="s1">&#39;memory&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">GB&quot;</span><span class="p">)</span>
    <span class="c1"># bf16 compiled runtime of the compiled full model is 729.65ms and peak memory  23.96GB</span>

    <span class="k">del</span> <span class="n">model_c</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a>
    <span class="n">model</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <span class="n">get_sam_model</span><span class="p">(</span><span class="kc">False</span><span class="p">,</span> <span class="n">batchsize</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module.to" title="torch.nn.Module.to" class="sphx-glr-backref-module-torch-nn sphx-glr-backref-type-py-method"><span class="n">model</span><span class="o">.</span><span class="n">to</span></a><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span></a><span class="p">)</span>
    <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="o">.</span><span class="n">to</span><span class="p">(</span><a href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype" title="torch.dtype" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span></a><span class="p">)</span>
    <span class="n">change_linear_weights_to_int8_dqtensors</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
    <span class="n">model_c</span> <span class="o">=</span> <a href="https://pytorch.org/docs/stable/generated/torch.compile.html#torch.compile" title="torch.compile" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-function"><span class="n">torch</span><span class="o">.</span><span class="n">compile</span></a><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;max-autotune&#39;</span><span class="p">)</span>
    <span class="n">quant_res</span> <span class="o">=</span> <span class="n">benchmark</span><span class="p">(</span><span class="n">model_c</span><span class="p">,</span> <a href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor" title="torch.Tensor" class="sphx-glr-backref-module-torch sphx-glr-backref-type-py-class sphx-glr-backref-instance"><span class="n">image</span></a><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;bf16 compiled runtime of the quantized full model is </span><span class="si">{</span><span class="n">quant_res</span><span class="p">[</span><span class="s1">&#39;time&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">ms and peak memory </span><span class="si">{</span><span class="n">quant_res</span><span class="p">[</span><span class="s1">&#39;memory&#39;</span><span class="p">]</span><span class="si">:</span><span class="s2"> 0.2f</span><span class="si">}</span><span class="s2">GB&quot;</span><span class="p">)</span>
    <span class="c1"># bf16 compiled runtime of the quantized full model is 677.28ms and peak memory  24.93GB</span>
<span class="k">except</span> <span class="ne">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;unable to run full model: &quot;</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
</pre></div>
</div>
<div class="sphx-glr-script-out highlight-none notranslate"><div class="highlight"><pre><span></span>AUTOTUNE convolution(16x3x1024x1024, 1280x3x16x16)
  triton_convolution_977 13.9607 ms 100.0%
  triton_convolution_982 17.6264 ms 79.2%
  triton_convolution_979 18.4125 ms 75.8%
  convolution 23.1427 ms 60.3%
  triton_convolution_976 23.7970 ms 58.7%
  triton_convolution_981 23.9197 ms 58.4%
  triton_convolution_980 26.7111 ms 52.3%
  triton_convolution_978 379.3695 ms 3.7%
SingleProcess AUTOTUNE benchmarking takes 4.7731 seconds and 0.0006 seconds precompiling
AUTOTUNE mm(78400x1280, 1280x3840)
  triton_mm_999 11.2180 ms 100.0%
  triton_mm_996 11.3444 ms 98.9%
  triton_mm_994 11.3730 ms 98.6%
  triton_mm_992 11.4590 ms 97.9%
  mm 11.7096 ms 95.8%
  triton_mm_997 11.7269 ms 95.7%
  triton_mm_993 11.7558 ms 95.4%
  triton_mm_989 11.8412 ms 94.7%
  triton_mm_990 11.9046 ms 94.2%
  triton_mm_1000 12.3647 ms 90.7%
SingleProcess AUTOTUNE benchmarking takes 3.5405 seconds and 0.0000 seconds precompiling
AUTOTUNE mm(78400x1280, 1280x1280)
  triton_mm_1081 3.7644 ms 100.0%
  triton_mm_1085 3.7681 ms 99.9%
  triton_mm_1088 3.7935 ms 99.2%
  triton_mm_1083 3.8135 ms 98.7%
  triton_mm_1082 3.8492 ms 97.8%
  triton_mm_1078 3.8540 ms 97.7%
  triton_mm_1086 3.8949 ms 96.7%
  triton_mm_1079 3.9418 ms 95.5%
  mm 3.9575 ms 95.1%
  triton_mm_1089 4.1570 ms 90.6%
SingleProcess AUTOTUNE benchmarking takes 2.6336 seconds and 0.0000 seconds precompiling
AUTOTUNE mm(65536x1280, 1280x5120)
  triton_mm_1107 12.4880 ms 100.0%
  triton_mm_1102 12.6728 ms 98.5%
  triton_mm_1100 12.7326 ms 98.1%
  triton_mm_1104 12.7379 ms 98.0%
  mm 13.0767 ms 95.5%
  triton_mm_1105 13.1688 ms 94.8%
  triton_mm_1097 13.1814 ms 94.7%
  triton_mm_1101 13.1855 ms 94.7%
  triton_mm_1098 13.3739 ms 93.4%
  triton_mm_1108 13.7748 ms 90.7%
SingleProcess AUTOTUNE benchmarking takes 3.6236 seconds and 0.0000 seconds precompiling
AUTOTUNE mm(65536x5120, 5120x1280)
  triton_mm_1126 12.3665 ms 100.0%
  mm 12.5518 ms 98.5%
  triton_mm_1121 12.6098 ms 98.1%
  triton_mm_1123 12.9038 ms 95.8%
  triton_mm_1124 12.9485 ms 95.5%
  triton_mm_1120 12.9545 ms 95.5%
  triton_mm_1119 13.0107 ms 95.0%
  triton_mm_1127 13.2372 ms 93.4%
  triton_mm_1116 13.2699 ms 93.2%
  triton_mm_1117 13.3624 ms 92.5%
SingleProcess AUTOTUNE benchmarking takes 3.7357 seconds and 0.0000 seconds precompiling
AUTOTUNE mm(65536x1280, 1280x3840)
  triton_mm_2021 9.4502 ms 100.0%
  triton_mm_2014 9.5524 ms 98.9%
  triton_mm_2018 9.5859 ms 98.6%
  triton_mm_2016 9.6001 ms 98.4%
  mm 9.7916 ms 96.5%
  triton_mm_2019 9.8831 ms 95.6%
  triton_mm_2011 9.9183 ms 95.3%
  triton_mm_2012 10.0645 ms 93.9%
  triton_mm_2015 10.1237 ms 93.3%
  triton_mm_2022 10.3447 ms 91.4%
SingleProcess AUTOTUNE benchmarking takes 3.2320 seconds and 0.0011 seconds precompiling
AUTOTUNE bmm(64x16384x80, 64x80x64)
  triton_bmm_2025 0.6099 ms 100.0%
  triton_bmm_2028 0.6151 ms 99.1%
  triton_bmm_2041 0.6169 ms 98.9%
  triton_bmm_2035 0.6177 ms 98.7%
  triton_bmm_2031 0.6180 ms 98.7%
  triton_bmm_2040 0.6218 ms 98.1%
  triton_bmm_2032 0.6266 ms 97.3%
  triton_bmm_2036 0.6269 ms 97.3%
  triton_bmm_2027 0.6319 ms 96.5%
  triton_bmm_2026 0.6419 ms 95.0%
SingleProcess AUTOTUNE benchmarking takes 2.3061 seconds and 0.0010 seconds precompiling
AUTOTUNE bmm(64x16384x80, 64x80x64)
  triton_bmm_2046 0.6895 ms 100.0%
  triton_bmm_2043 0.6915 ms 99.7%
  triton_bmm_2054 0.6932 ms 99.5%
  triton_bmm_2050 0.6939 ms 99.4%
  triton_bmm_2045 0.7395 ms 93.2%
  triton_bmm_2044 0.7567 ms 91.1%
  triton_bmm_2058 0.8376 ms 82.3%
  triton_bmm_2049 0.8397 ms 82.1%
  triton_bmm_2053 0.8404 ms 82.0%
  triton_bmm_2059 0.8571 ms 80.4%
SingleProcess AUTOTUNE benchmarking takes 2.3564 seconds and 0.0011 seconds precompiling
AUTOTUNE mm(65536x1280, 1280x1280)
  triton_mm_2069 3.1350 ms 100.0%
  triton_mm_2076 3.1586 ms 99.3%
  triton_mm_2073 3.1630 ms 99.1%
  triton_mm_2071 3.1979 ms 98.0%
  triton_mm_2070 3.2624 ms 96.1%
  triton_mm_2066 3.2765 ms 95.7%
  triton_mm_2074 3.2799 ms 95.6%
  mm 3.2832 ms 95.5%
  triton_mm_2067 3.3303 ms 94.1%
  triton_mm_2077 3.4603 ms 90.6%
SingleProcess AUTOTUNE benchmarking takes 2.4738 seconds and 0.0012 seconds precompiling
AUTOTUNE convolution(16x1280x64x64, 256x1280x1x1)
  convolution 0.7878 ms 100.0%
  triton_convolution_5519 0.8031 ms 98.1%
  triton_convolution_5524 0.8441 ms 93.3%
  triton_convolution_5522 0.8735 ms 90.2%
  triton_convolution_5525 1.3756 ms 57.3%
  triton_convolution_5520 1.4217 ms 55.4%
  triton_convolution_5523 1.4416 ms 54.6%
  conv1x1_via_mm 2.2829 ms 34.5%
  triton_convolution_5521 2.4049 ms 32.8%
SingleProcess AUTOTUNE benchmarking takes 1.1604 seconds and 0.0005 seconds precompiling
AUTOTUNE convolution(16x256x64x64, 256x256x3x3)
  convolution 1.4445 ms 100.0%
  triton_convolution_5527 2.9625 ms 48.8%
  triton_convolution_5532 3.0714 ms 47.0%
  triton_convolution_5530 3.1516 ms 45.8%
  triton_convolution_5529 3.6626 ms 39.4%
  triton_convolution_5531 6.1739 ms 23.4%
  triton_convolution_5526 8.3369 ms 17.3%
  triton_convolution_5528 9.2888 ms 15.6%
SingleProcess AUTOTUNE benchmarking takes 1.1901 seconds and 0.0005 seconds precompiling
unable to run full model:  CUDA out of memory. Tried to allocate 8.00 GiB. GPU 0 has a total capacity of 21.98 GiB of which 4.28 GiB is free. Process 111853 has 17.67 GiB memory in use. Of the allocated memory 16.73 GiB is allocated by PyTorch, with 511.96 MiB allocated in private pools (e.g., CUDA Graphs), and 553.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
</pre></div>
</div>
</div>
<div class="section" id="conclusion">
<h2>Conclusion<a class="headerlink" href="#conclusion" title="Permalink to this heading">¶</a></h2>
<p>In this tutorial, we have learned about the quantization and optimization techniques
on the example of the segment anything model.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># In the end, we achieved a full-model apples to apples quantization speedup</span>
<span class="c1"># of about 7.7% on batch size 16 (677.28ms to 729.65ms). We can push this a</span>
<span class="c1"># bit further by increasing the batch size and optimizing other parts of</span>
<span class="c1"># the model. For example, this can be done with some form of flash attention.</span>
<span class="c1">#</span>
<span class="c1"># For more information visit</span>
<span class="c1"># `torchao &lt;https://github.com/pytorch-labs/ao&gt;`_ and try it on your own</span>
<span class="c1"># models.</span>
<span class="c1">#</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 9 minutes  51.830 seconds)</p>
<div class="sphx-glr-footer sphx-glr-footer-example docutils container" id="sphx-glr-download-prototype-gpu-quantization-torchao-tutorial-py">
<div class="sphx-glr-download sphx-glr-download-python docutils container">
<p><a class="reference download internal" download="" href="../_downloads/0a0adb045e37300c70e9f07380224243/gpu_quantization_torchao_tutorial.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">gpu_quantization_torchao_tutorial.py</span></code></a></p>
</div>
<div class="sphx-glr-download sphx-glr-download-jupyter docutils container">
<p><a class="reference download internal" download="" href="../_downloads/6011ce860c893c5ee96624c75d548133/gpu_quantization_torchao_tutorial.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">gpu_quantization_torchao_tutorial.ipynb</span></code></a></p>
</div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.github.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


             </article>
             
            </div>
            <footer>
  

  

    <hr class="rating-hr hr-top">
      <div class="rating-container">
        <div class="rating-prompt">Rate this Tutorial</div>
        <div class="stars-outer">
          <i class="far fa-star" title="1 Star" data-behavior="tutorial-rating" data-count="1"></i>
          <i class="far fa-star" title="2 Stars" data-behavior="tutorial-rating" data-count="2"></i>
          <i class="far fa-star" title="3 Stars" data-behavior="tutorial-rating" data-count="3"></i>
          <i class="far fa-star" title="4 Stars" data-behavior="tutorial-rating" data-count="4"></i>
          <i class="far fa-star" title="5 Stars" data-behavior="tutorial-rating" data-count="5"></i>
        </div>
      </div>
    <hr class="rating-hr hr-bottom"/>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2024, PyTorch.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
<script>
if((window.location.href.indexOf("/prototype/")!= -1) && (window.location.href.indexOf("/prototype/prototype_index")< 1))
  {
    var div = '<div class="admonition note"><p class="admonition-title">Note</p><p><i class="fa fa-flask" aria-hidden="true">&nbsp</i> This tutorial describes a prototype feature. Prototype features are typically not available as part of binary distributions like PyPI or Conda, except sometimes behind run-time flags, and are at an early stage for feedback and testing.</p></div>'
    document.getElementById("pytorch-article").insertAdjacentHTML('afterBegin', div)
  } 
</script>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">(prototype) GPU Quantization with TorchAO</a><ul>
<li><a class="reference internal" href="#set-up-your-environment">Set up Your Environment</a></li>
<li><a class="reference internal" href="#conclusion">Conclusion</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
         <script src="../_static/jquery.js"></script>
         <script src="../_static/underscore.js"></script>
         <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
         <script src="../_static/doctools.js"></script>
         <script src="../_static/clipboard.min.js"></script>
         <script src="../_static/copybutton.js"></script>
         <script src="../_static/katex.min.js"></script>
         <script src="../_static/auto-render.min.js"></script>
         <script src="../_static/katex_autorenderer.js"></script>
         <script src="../_static/design-tabs.js"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>

// Helper function to make it easier to call dataLayer.push() 
function gtag(){window.dataLayer.push(arguments);}

//add microsoft link

if(window.location.href.indexOf("/beginner/basics/")!= -1)
{
  var url="https://docs.microsoft.com/learn/paths/pytorch-fundamentals/?wt.mc_id=aiml-7486-cxa";
  switch(window.location.pathname.split("/").pop().replace('.html',''))
  {
    case"quickstart_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/9-quickstart?WT.mc_id=aiml-7486-cxa";
      break;
    case"tensorqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/2-tensors?WT.mc_id=aiml-7486-cxa";
      break;
    case"data_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/3-data?WT.mc_id=aiml-7486-cxa";
      break;
    case"transforms_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/4-transforms?WT.mc_id=aiml-7486-cxa";
      break;
    case"buildmodel_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/5-model?WT.mc_id=aiml-7486-cxa";
      break;
    case"autogradqs_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/6-autograd?WT.mc_id=aiml-7486-cxa";
      break;
    case"optimization_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/7-optimization?WT.mc_id=aiml-7486-cxa";
      break;
    case"saveloadrun_tutorial":
      url="https://docs.microsoft.com/learn/modules/intro-machine-learning-pytorch/8-inference?WT.mc_id=aiml-7486-cxa";
    }
    
    $(".pytorch-call-to-action-links").children().first().before("<a href="+url+' data-behavior="call-to-action-event" data-response="Run in Microsoft Learn" target="_blank"><div id="microsoft-learn-link" style="padding-bottom: 0.625rem;border-bottom: 1px solid #f3f4f7;padding-right: 2.5rem;display: -webkit-box;  display: -ms-flexbox; display: flex; -webkit-box-align: center;-ms-flex-align: center;align-items: center;"><img class="call-to-action-img" src="../../_static/images/microsoft-logo.svg"/><div class="call-to-action-desktop-view">Run in Microsoft Learn</div><div class="call-to-action-mobile-view">Learn</div></div></a>')
  }

  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    gtag('event', 'click', {
      'event_category': $(this).attr("data-response"),
      'event_label': $("h1").first().text(),
      'tutorial_link': window.location.href
    });
   });

   $("[data-behavior='tutorial-rating']").on('click', function(){
    fbq('trackCustom', "Tutorial Rating", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      rating: $(this).attr("data-count")
    });
    gtag('event', 'click', {
      'event_category': 'Tutorial Rating',
      'event_label': $("h1").first().text(),
      'value': $(this).attr("data-count"),
      'customEvent:Rating': $(this).attr("data-count") // send to GA custom dimension customEvent:Rating.
    });
   });

   if (location.pathname == "/") {
     $(".rating-container").hide();
     $(".hr-bottom").hide();
   }


</script>

<noscript>
  <img height="1" width="1"
  src="https://www.facebook.com/tr?id=243028289693773&ev=PageView
  &noscript=1"/>
</noscript>

<script type="text/javascript">
  var collapsedSections = ['PyTorch Recipes', 'Learning PyTorch', 'Image and Video', 'Audio', 'Text', 'Backends', 'Reinforcement Learning', 'Deploying PyTorch Models in Production', 'Profiling PyTorch', 'Code Transforms with FX', 'Frontend APIs', 'Extending PyTorch', 'Model Optimization', 'Parallel and Distributed Training', 'Edge with ExecuTorch', 'Recommendation Systems', 'Multimodality'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">Stay up to date</li>
            <li><a href="https://www.facebook.com/pytorch" target="_blank">Facebook</a></li>
            <li><a href="https://twitter.com/pytorch" target="_blank">Twitter</a></li>
            <li><a href="https://www.youtube.com/pytorch" target="_blank">YouTube</a></li>
            <li><a href="https://www.linkedin.com/company/pytorch" target="_blank">LinkedIn</a></li>
          </ul>  
          </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title">PyTorch Podcasts</li>
            <li><a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5" target="_blank">Spotify</a></li>
            <li><a href="https://podcasts.apple.com/us/podcast/pytorch-developer-podcast/id1566080008" target="_blank">Apple</a></li>
            <li><a href="https://www.google.com/podcasts?feed=aHR0cHM6Ly9mZWVkcy5zaW1wbGVjYXN0LmNvbS9PQjVGa0lsOA%3D%3D" target="_blank">Google</a></li>
            <li><a href="https://music.amazon.com/podcasts/7a4e6f0e-26c2-49e9-a478-41bd244197d0/PyTorch-Developer-Podcast?" target="_blank">Amazon</a></li>
          </ul>
         </div>
        </div>
        
        <div class="privacy-policy">
          <ul>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/terms/" target="_blank">Terms</a></li>
            <li class="privacy-policy-links">|</li>
            <li class="privacy-policy-links"><a href="https://www.linuxfoundation.org/privacy-policy/" target="_blank">Privacy</a></li>
          </ul>
        </div>
        <div class="copyright">
        <p>© Copyright The Linux Foundation. The PyTorch Foundation is a project of The Linux Foundation.
          For web site terms of use, trademark policy and other policies applicable to The PyTorch Foundation please see
          <a href="https://www.linuxfoundation.org/policies/">www.linuxfoundation.org/policies/</a>. The PyTorch Foundation supports the PyTorch open source
          project, which has been established as PyTorch Project a Series of LF Projects, LLC. For policies applicable to the PyTorch Project a Series of LF Projects, LLC,
          please see <a href="https://www.lfprojects.org/policies/">www.lfprojects.org/policies/</a>.</p>
      </div>
     </div>

  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
           <li class="resources-mobile-menu-title">
             <a>Learn</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/get-started">Get Started</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials">Tutorials</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Learn the Basics</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/recipes/recipes_index.html">PyTorch Recipes</a>
             </li>
             <li>
               <a href="https://pytorch.org/tutorials/beginner/introyt.html">Introduction to PyTorch - YouTube Series</a>
             </li>
           </ul>
           <li class="resources-mobile-menu-title">
             <a>Ecosystem</a>
           </li>
           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/ecosystem">Tools</a>
             </li>
             <li>
               <a href="https://pytorch.org/#community-module">Community</a>
             </li>
             <li>
               <a href="https://discuss.pytorch.org/">Forums</a>
             </li>
             <li>
               <a href="https://pytorch.org/resources">Developer Resources</a>
             </li>
             <li>
               <a href="https://pytorch.org/ecosystem/contributor-awards-2023">Contributor Awards - 2023</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Edge</a>
           </li>

           <ul class="resources-mobile-menu-items">
             <li>
               <a href="https://pytorch.org/edge">About PyTorch Edge</a>
             </li>
             
             <li>
               <a href="https://pytorch.org/executorch-overview">ExecuTorch</a>
             </li>
           </ul>

           <li class="resources-mobile-menu-title">
             <a>Docs</a>
           </li>

           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/pytorch-domains">PyTorch Domains</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            <a>Blog & News</a>
          </li>
            
           <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/blog/">PyTorch Blog</a>
            </li>
            <li>
              <a href="https://pytorch.org/community-blog">Community Blog</a>
            </li>

            <li>
              <a href="https://pytorch.org/videos">Videos</a>
            </li>

            <li>
              <a href="https://pytorch.org/community-stories">Community Stories</a>
            </li>
            <li>
              <a href="https://pytorch.org/events">Events</a>
            </li>
          </ul>
          
          <li class="resources-mobile-menu-title">
            <a>About</a>
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/foundation">PyTorch Foundation</a>
            </li>
            <li>
              <a href="https://pytorch.org/governing-board">Governing Board</a>
            </li>
          </ul>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>